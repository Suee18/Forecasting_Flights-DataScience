{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662e300b",
   "metadata": {},
   "source": [
    "# 3M dataset - Data Preprocessing\n",
    "\n",
    " cleansing 3M flight records for delay prediction modeling.\n",
    "\n",
    "## Contents\n",
    "1. [Data Loading](#loading)\n",
    "2. [Handling cancelled flihgts](#cancelled)\n",
    "3. [Save Processed Dataset](#save)\n",
    "4. [Handling Data Types](#data_types)\n",
    "5. [Handling Missing Values](#missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c1bf8",
   "metadata": {},
   "source": [
    "## 1. Data Loading <a id='loading'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5dbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "from src.data import loader, processor\n",
    "from src.visualization import exploratory_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e27303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data file: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\raw\\flights_sample_3m.csv\n",
      "Processed data directory: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "raw_file_path = os.path.join(PROJECT_ROOT, 'data', 'raw', 'flights_sample_3m.csv')\n",
    "processed_dir = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Input data file: {raw_file_path}\")\n",
    "print(f\"Processed data directory: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cd3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AIRLINE_DOT</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>DOT_CODE</th>\n",
       "      <th>FL_NUMBER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DELAY_DUE_CARRIER</th>\n",
       "      <th>DELAY_DUE_WEATHER</th>\n",
       "      <th>DELAY_DUE_NAS</th>\n",
       "      <th>DELAY_DUE_SECURITY</th>\n",
       "      <th>DELAY_DUE_LATE_AIRCRAFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>United Air Lines Inc.: UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>1562</td>\n",
       "      <td>FLL</td>\n",
       "      <td>Fort Lauderdale, FL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>19790</td>\n",
       "      <td>1149</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>United Air Lines Inc.: UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>19977</td>\n",
       "      <td>459</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>19790</td>\n",
       "      <td>2295</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>Spirit Air Lines: NK</td>\n",
       "      <td>NK</td>\n",
       "      <td>20416</td>\n",
       "      <td>407</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE                AIRLINE                AIRLINE_DOT AIRLINE_CODE  \\\n",
       "0  2019-01-09  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n",
       "1  2022-11-19   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n",
       "2  2022-07-22  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n",
       "3  2023-03-06   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n",
       "4  2020-02-23       Spirit Air Lines       Spirit Air Lines: NK           NK   \n",
       "\n",
       "   DOT_CODE  FL_NUMBER ORIGIN          ORIGIN_CITY DEST  \\\n",
       "0     19977       1562    FLL  Fort Lauderdale, FL  EWR   \n",
       "1     19790       1149    MSP      Minneapolis, MN  SEA   \n",
       "2     19977        459    DEN           Denver, CO  MSP   \n",
       "3     19790       2295    MSP      Minneapolis, MN  SFO   \n",
       "4     20416        407    MCO          Orlando, FL  DFW   \n",
       "\n",
       "               DEST_CITY  ...  DIVERTED  CRS_ELAPSED_TIME  ELAPSED_TIME  \\\n",
       "0             Newark, NJ  ...       0.0             186.0         176.0   \n",
       "1            Seattle, WA  ...       0.0             235.0         236.0   \n",
       "2        Minneapolis, MN  ...       0.0             118.0         112.0   \n",
       "3      San Francisco, CA  ...       0.0             260.0         285.0   \n",
       "4  Dallas/Fort Worth, TX  ...       0.0             181.0         182.0   \n",
       "\n",
       "   AIR_TIME  DISTANCE  DELAY_DUE_CARRIER  DELAY_DUE_WEATHER  DELAY_DUE_NAS  \\\n",
       "0     153.0    1065.0                NaN                NaN            NaN   \n",
       "1     189.0    1399.0                NaN                NaN            NaN   \n",
       "2      87.0     680.0                NaN                NaN            NaN   \n",
       "3     249.0    1589.0                0.0                0.0           24.0   \n",
       "4     153.0     985.0                NaN                NaN            NaN   \n",
       "\n",
       "   DELAY_DUE_SECURITY  DELAY_DUE_LATE_AIRCRAFT  \n",
       "0                 NaN                      NaN  \n",
       "1                 NaN                      NaN  \n",
       "2                 NaN                      NaN  \n",
       "3                 0.0                      0.0  \n",
       "4                 NaN                      NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to process data in chunks to handle 3M rows efficiently\n",
    "def process_data_in_chunks(file_path, chunksize=100000):\n",
    "    \"\"\"\n",
    "    Generator function to process the data in chunks\n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        chunksize: Number of rows to process at a time\n",
    "    Yields:\n",
    "        Processed DataFrame chunks\n",
    "    \"\"\"\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        yield chunk\n",
    "\n",
    "first_chunk = next(process_data_in_chunks(raw_file_path, chunksize=5))\n",
    "first_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93585f78",
   "metadata": {},
   "source": [
    "## 2. Handling Cancelled Flights <a id='cancelled'></a>\n",
    "\n",
    "As we're focusing on predicting delays for flights that actually operated, we'll separate cancelled flights from our analysis dataset. Cancelled flights represent a different phenomenon and would confuse our delay prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1,000,000 rows...\n",
      "Processed 2,000,000 rows...\n",
      "Processed 3,000,000 rows...\n",
      "Total Flights: 3,000,000\n",
      "Cancelled Flights: 79,140 (2.64%)\n",
      "\n",
      "Cancellation Codes:\n",
      "  B: 28,772 flights\n",
      "  D: 24,417 flights\n",
      "  A: 19,476 flights\n",
      "  C: 6,475 flights\n",
      "\n",
      "Cancellation Code Meanings:\n",
      "  A: Carrier\n",
      "  B: Weather\n",
      "  C: National Air System\n",
      "  D: Security\n"
     ]
    }
   ],
   "source": [
    "# First, let's analyze how many flights were cancelled\n",
    "def analyze_cancellations(file_path, chunksize=100000):\n",
    "    cancelled_count = 0\n",
    "    total_count = 0\n",
    "    cancellation_codes = {}\n",
    "    \n",
    "    # Process in chunks to handle the large dataset\n",
    "    for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):\n",
    "        total_count += len(chunk)\n",
    "        \n",
    "        # Count cancelled flights\n",
    "        cancelled_in_chunk = chunk[chunk['CANCELLED'] == 1.0]\n",
    "        cancelled_count += len(cancelled_in_chunk)\n",
    "        \n",
    "        # Track cancellation reasons\n",
    "        code_counts = cancelled_in_chunk['CANCELLATION_CODE'].value_counts()\n",
    "        for code, count in code_counts.items():\n",
    "            if code in cancellation_codes:\n",
    "                cancellation_codes[code] += count\n",
    "            else:\n",
    "                cancellation_codes[code] = count\n",
    "                \n",
    "        # Print progress\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Processed {(i+1)*chunksize:,} rows...\")\n",
    "    \n",
    "    # Calculate percentage\n",
    "    cancelled_pct = (cancelled_count / total_count) * 100 if total_count > 0 else 0\n",
    "    \n",
    "    # Create a summary dictionary\n",
    "    summary = {\n",
    "        'total_flights': total_count,\n",
    "        'cancelled_flights': cancelled_count,\n",
    "        'cancelled_percentage': cancelled_pct,\n",
    "        'cancellation_codes': cancellation_codes\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Run the analysis\n",
    "cancellation_summary = analyze_cancellations(raw_file_path)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total Flights: {cancellation_summary['total_flights']:,}\")\n",
    "print(f\"Cancelled Flights: {cancellation_summary['cancelled_flights']:,} ({cancellation_summary['cancelled_percentage']:.2f}%)\")\n",
    "print(\"\\nCancellation Codes:\")\n",
    "for code, count in cancellation_summary['cancellation_codes'].items():\n",
    "    print(f\"  {code}: {count:,} flights\")\n",
    "    \n",
    "# Explanation of cancellation codes\n",
    "code_meanings = {\n",
    "    'A': 'Carrier',\n",
    "    'B': 'Weather',\n",
    "    'C': 'National Air System',\n",
    "    'D': 'Security'\n",
    "}\n",
    "\n",
    "print(\"\\nCancellation Code Meanings:\")\n",
    "for code, meaning in code_meanings.items():\n",
    "    print(f\"  {code}: {meaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2d3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out cancelled flights...\n",
      "Processed 500,000 rows...\n",
      "Processed 1,000,000 rows...\n",
      "Processed 1,500,000 rows...\n",
      "Processed 2,000,000 rows...\n",
      "Processed 2,500,000 rows...\n",
      "Processed 3,000,000 rows...\n",
      "\n",
      "Filtering complete!\n",
      "Total rows processed: 3,000,000\n",
      "Operational flights: 2,920,860\n",
      "Cancelled flights removed: 79,140 (2.64%)\n",
      "\n",
      "Operational flights saved to: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\\operational_flights.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to filter out cancelled flights and save operational flights\n",
    "def filter_operational_flights(input_path, output_path, chunksize=100000):\n",
    "    \"\"\"\n",
    "    Filter the dataset to include only operational flights (not cancelled)\n",
    "    and save it to a new CSV file.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to the input CSV file\n",
    "        output_path: Path to save the filtered CSV file\n",
    "        chunksize: Number of rows to process at a time\n",
    "    \"\"\"\n",
    "    # Track statistics\n",
    "    total_rows = 0\n",
    "    operational_rows = 0\n",
    "    \n",
    "    # Process the first chunk to get the header\n",
    "    first_chunk = True\n",
    "    \n",
    "    # Process in chunks\n",
    "    for i, chunk in enumerate(pd.read_csv(input_path, chunksize=chunksize)):\n",
    "        # Update counts\n",
    "        total_rows += len(chunk)\n",
    "        \n",
    "        # Filter out cancelled flights\n",
    "        operational_chunk = chunk[chunk['CANCELLED'] != 1.0]\n",
    "        operational_rows += len(operational_chunk)\n",
    "        \n",
    "        # Save the chunk (append mode after first chunk)\n",
    "        if first_chunk:\n",
    "            operational_chunk.to_csv(output_path, index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            operational_chunk.to_csv(output_path, mode='a', header=False, index=False)\n",
    "        \n",
    "        # Print progress\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"Processed {(i+1)*chunksize:,} rows...\")\n",
    "    \n",
    "    # Return statistics\n",
    "    return {\n",
    "        'total_rows': total_rows,\n",
    "        'operational_rows': operational_rows,\n",
    "        'filtered_rows': total_rows - operational_rows,\n",
    "        'filtered_percentage': ((total_rows - operational_rows) / total_rows) * 100 if total_rows > 0 else 0\n",
    "    }\n",
    "\n",
    "operational_flights_path = os.path.join(processed_dir, 'operational_flights.csv')\n",
    "\n",
    "# Run the filtering process\n",
    "print(\"Filtering out cancelled flights...\")\n",
    "filter_stats = filter_operational_flights(raw_file_path, operational_flights_path)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nFiltering complete!\")\n",
    "print(f\"Total rows processed: {filter_stats['total_rows']:,}\")\n",
    "print(f\"Operational flights: {filter_stats['operational_rows']:,}\")\n",
    "print(f\"Cancelled flights removed: {filter_stats['filtered_rows']:,} ({filter_stats['filtered_percentage']:.2f}%)\")\n",
    "print(f\"\\nOperational flights saved to: {operational_flights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ca990",
   "metadata": {},
   "source": [
    "## 4. Handling Data Types<a id='data_types'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4503d44",
   "metadata": {},
   "source": [
    "changing some features data type to datetime datatype (takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 500,000 rows so far...\n",
      "✅ Processed 1,000,000 rows so far...\n",
      "✅ Processed 1,500,000 rows so far...\n",
      "✅ Processed 2,000,000 rows so far...\n",
      "✅ Processed 2,500,000 rows so far...\n",
      "✅ Processed 3,000,000 rows so far...\n",
      "\n",
      "🏁 Done! Cleaned file saved to: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\\operational_flights.csv\n",
      "📊 Total rows processed: 2,920,860\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def convert_flight_times_to_datetime(input_path, chunksize=100_000):\n",
    "    \"\"\"\n",
    "    Efficiently convert FL_DATE and hhmm time columns to datetime for large CSVs in chunks.\n",
    "    Saves results to a temp file and replaces the original once complete.\n",
    "    \"\"\"\n",
    "    time_columns = ['DEP_TIME', 'ARR_TIME', 'CRS_DEP_TIME', 'CRS_ARR_TIME', 'WHEELS_OFF', 'WHEELS_ON']\n",
    "\n",
    "    # Create temporary file\n",
    "    dir_name = os.path.dirname(input_path)\n",
    "    temp_fd, temp_path = tempfile.mkstemp(dir=dir_name, suffix=\".csv\")\n",
    "    os.close(temp_fd)\n",
    "\n",
    "    total_rows = 0\n",
    "    first_chunk = True\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(input_path, chunksize=chunksize)):\n",
    "        total_rows += len(chunk)\n",
    "\n",
    "        # Convert FL_DATE to datetime\n",
    "        chunk['FL_DATE'] = pd.to_datetime(chunk['FL_DATE'], errors='coerce')\n",
    "\n",
    "        for col in time_columns:\n",
    "            if col in chunk.columns:\n",
    "                # Work on a copy of the time column as strings\n",
    "                time_raw = pd.to_numeric(chunk[col], errors='coerce').dropna().astype(int).astype(str).str.zfill(4)\n",
    "\n",
    "                # Prepare full datetime strings\n",
    "                valid_mask = chunk['FL_DATE'].notna() & chunk[col].notna()\n",
    "                combined_str = (\n",
    "                    chunk.loc[valid_mask, 'FL_DATE'].dt.strftime('%Y-%m-%d') + ' ' +\n",
    "                    time_raw.loc[valid_mask].str[:2] + ':' + time_raw.loc[valid_mask].str[2:]\n",
    "                )\n",
    "\n",
    "                # Initialize as NaT\n",
    "                chunk[col] = pd.NaT\n",
    "\n",
    "                # Assign parsed datetime values\n",
    "                chunk.loc[valid_mask, col] = pd.to_datetime(combined_str, errors='coerce')\n",
    "\n",
    "        # Write chunk to temp file\n",
    "        if first_chunk:\n",
    "            chunk.to_csv(temp_path, index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            chunk.to_csv(temp_path, mode='a', header=False, index=False)\n",
    "\n",
    "        # Print progress every 5 chunks\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"✅ Processed {(i + 1) * chunksize:,} rows so far...\")\n",
    "\n",
    "    # Replace original file\n",
    "    shutil.move(temp_path, input_path)\n",
    "    print(f\"\\n Cleaned file saved to: {input_path}\")\n",
    "    print(f\"📊 Total rows processed: {total_rows:,}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "convert_flight_times_to_datetime(operational_flights_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166e241",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values <a id='missing_values'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "255cf0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 500,000 rows so far...\n",
      "✅ Processed 1,000,000 rows so far...\n",
      "✅ Processed 1,500,000 rows so far...\n",
      "✅ Processed 2,000,000 rows so far...\n",
      "✅ Processed 2,500,000 rows so far...\n",
      "✅ Processed 3,000,000 rows so far...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANCELLATION_CODE</td>\n",
       "      <td>float64</td>\n",
       "      <td>2920860</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DELAY_DUE_LATE_AIRCRAFT</td>\n",
       "      <td>float64</td>\n",
       "      <td>2386997</td>\n",
       "      <td>81.722404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DELAY_DUE_CARRIER</td>\n",
       "      <td>float64</td>\n",
       "      <td>2386997</td>\n",
       "      <td>81.722404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DELAY_DUE_SECURITY</td>\n",
       "      <td>float64</td>\n",
       "      <td>2386997</td>\n",
       "      <td>81.722404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DELAY_DUE_NAS</td>\n",
       "      <td>float64</td>\n",
       "      <td>2386997</td>\n",
       "      <td>81.722404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DELAY_DUE_WEATHER</td>\n",
       "      <td>float64</td>\n",
       "      <td>2386997</td>\n",
       "      <td>81.722404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARR_DELAY</td>\n",
       "      <td>float64</td>\n",
       "      <td>7058</td>\n",
       "      <td>0.241641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELAPSED_TIME</td>\n",
       "      <td>float64</td>\n",
       "      <td>7058</td>\n",
       "      <td>0.241641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIR_TIME</td>\n",
       "      <td>float64</td>\n",
       "      <td>7058</td>\n",
       "      <td>0.241641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARR_TIME</td>\n",
       "      <td>object</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.075937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WHEELS_ON</td>\n",
       "      <td>object</td>\n",
       "      <td>1913</td>\n",
       "      <td>0.065494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TAXI_IN</td>\n",
       "      <td>float64</td>\n",
       "      <td>804</td>\n",
       "      <td>0.027526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WHEELS_OFF</td>\n",
       "      <td>object</td>\n",
       "      <td>401</td>\n",
       "      <td>0.013729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DEP_TIME</td>\n",
       "      <td>object</td>\n",
       "      <td>242</td>\n",
       "      <td>0.008285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CRS_ARR_TIME</td>\n",
       "      <td>object</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FL_DATE</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEP_DELAY</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAXI_OUT</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DEST_CITY</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CRS_DEP_TIME</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DEST</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FL_NUMBER</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ORIGIN_CITY</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AIRLINE_CODE</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AIRLINE_DOT</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AIRLINE</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DOT_CODE</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CRS_ELAPSED_TIME</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DIVERTED</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Column Data_Type  Missing_Count  Missing_Percentage\n",
       "0         CANCELLATION_CODE   float64        2920860          100.000000\n",
       "1   DELAY_DUE_LATE_AIRCRAFT   float64        2386997           81.722404\n",
       "2         DELAY_DUE_CARRIER   float64        2386997           81.722404\n",
       "3        DELAY_DUE_SECURITY   float64        2386997           81.722404\n",
       "4             DELAY_DUE_NAS   float64        2386997           81.722404\n",
       "5         DELAY_DUE_WEATHER   float64        2386997           81.722404\n",
       "6                 ARR_DELAY   float64           7058            0.241641\n",
       "7              ELAPSED_TIME   float64           7058            0.241641\n",
       "8                  AIR_TIME   float64           7058            0.241641\n",
       "9                  ARR_TIME    object           2218            0.075937\n",
       "10                WHEELS_ON    object           1913            0.065494\n",
       "11                  TAXI_IN   float64            804            0.027526\n",
       "12               WHEELS_OFF    object            401            0.013729\n",
       "13                 DEP_TIME    object            242            0.008285\n",
       "14             CRS_ARR_TIME    object             13            0.000445\n",
       "15                  FL_DATE    object              0            0.000000\n",
       "16                DEP_DELAY   float64              0            0.000000\n",
       "17                 TAXI_OUT   float64              0            0.000000\n",
       "18                DEST_CITY    object              0            0.000000\n",
       "19             CRS_DEP_TIME    object              0            0.000000\n",
       "20                     DEST    object              0            0.000000\n",
       "21                FL_NUMBER     int64              0            0.000000\n",
       "22                   ORIGIN    object              0            0.000000\n",
       "23              ORIGIN_CITY    object              0            0.000000\n",
       "24             AIRLINE_CODE    object              0            0.000000\n",
       "25              AIRLINE_DOT    object              0            0.000000\n",
       "26                  AIRLINE    object              0            0.000000\n",
       "27                 DOT_CODE     int64              0            0.000000\n",
       "28         CRS_ELAPSED_TIME   float64              0            0.000000\n",
       "29                 DIVERTED   float64              0            0.000000\n",
       "30                CANCELLED   float64              0            0.000000\n",
       "31                 DISTANCE   float64              0            0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_missing_values_in_chunks(file_path, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Processes a large CSV file in chunks to compute missing values per column.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the input CSV file.\n",
    "        chunk_size: Number of rows to process per chunk.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame summarizing missing value counts and percentages per column.\n",
    "    \"\"\"\n",
    "    total_rows = 0\n",
    "    missing_counts = {}\n",
    "    data_types = None\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "        total_rows += len(chunk)\n",
    "\n",
    "        if i == 0:\n",
    "            data_types = chunk.dtypes\n",
    "\n",
    "        for column in chunk.columns:\n",
    "            if column not in missing_counts:\n",
    "                missing_counts[column] = 0\n",
    "            missing_counts[column] += chunk[column].isna().sum()\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"✅ Processed {(i + 1) * chunk_size:,} rows so far...\")\n",
    "\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Column': list(missing_counts.keys()),\n",
    "        'Data_Type': [data_types[col] for col in missing_counts.keys()],\n",
    "        'Missing_Count': list(missing_counts.values())\n",
    "    })\n",
    "\n",
    "    missing_summary['Missing_Percentage'] = (missing_summary['Missing_Count'] / total_rows) * 100\n",
    "    missing_summary = missing_summary.sort_values(by='Missing_Percentage', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return missing_summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "operational_flights_path = os.path.join(processed_dir, 'operational_flights.csv')\n",
    "missing_summary = check_missing_values_in_chunks(operational_flights_path, chunk_size=100000) \n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d1a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Input file: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\\operational_flights.csv\n",
      "📁 Temp output file: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\\operational_flights_cleaned.csv\n",
      "✅ Processed 500,000 rows so far...\n",
      "✅ Processed 1,000,000 rows so far...\n",
      "✅ Processed 1,500,000 rows so far...\n",
      "✅ Processed 2,000,000 rows so far...\n",
      "✅ Processed 2,500,000 rows so far...\n",
      "✅ Processed 3,000,000 rows so far...\n",
      "\n",
      "===== FINAL CLEANING SUMMARY =====\n",
      "Total chunks processed: 30\n",
      "Total rows processed: 2920860\n",
      "\n",
      "Delay columns filled with 0:\n",
      "  DELAY_DUE_CARRIER: 2386997 values filled\n",
      "  DELAY_DUE_WEATHER: 2386997 values filled\n",
      "  DELAY_DUE_NAS: 2386997 values filled\n",
      "  DELAY_DUE_SECURITY: 2386997 values filled\n",
      "  DELAY_DUE_LATE_AIRCRAFT: 2386997 values filled\n",
      "\n",
      "Numeric columns filled with median:\n",
      "  TAXI_IN: 804 values filled, median used = 6.0000\n",
      "  ARR_DELAY: 7058 values filled, median used = -7.0000\n",
      "  ELAPSED_TIME: 7058 values filled, median used = 120.0000\n",
      "  AIR_TIME: 7058 values filled, median used = 95.0000\n",
      "\n",
      "Categorical columns filled with mode:\n",
      "  DEP_TIME: 242 values filled, mode used = 2019-08-07 05:58:00\n",
      "  WHEELS_OFF: 401 values filled, mode used = 2019-09-09 21:04:00\n",
      "  WHEELS_ON: 1913 values filled, mode used = 2019-02-28 21:27:00\n",
      "  CRS_ARR_TIME: 13 values filled, mode used = 2019-09-28 13:25:00\n",
      "  ARR_TIME: 2218 values filled, mode used = 2019-03-04 12:03:00\n",
      "\n",
      "✅ Original file replaced with cleaned data: c:\\Users\\HP\\Desktop\\Forecasting_Flights-DataScience\\data\\processed\\operational_flights.csv\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def handle_missing_values(file_path, chunk_size=100000):\n",
    "    abs_input = os.path.abspath(file_path)\n",
    "    output_path = abs_input.replace(\".csv\", \"_cleaned.csv\")\n",
    "    print(f\"\\n📝 Input file: {abs_input}\")\n",
    "    print(f\"📁 Temp output file: {output_path}\")\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "\n",
    "    total_rows_processed = 0\n",
    "    chunk_count = 0\n",
    "\n",
    "    stats = {\n",
    "        'delay': {},\n",
    "        'numeric': {},\n",
    "        'categorical': {},\n",
    "        'datetime': {}\n",
    "    }\n",
    "\n",
    "    datetime_medians = {}\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(abs_input, chunksize=chunk_size, parse_dates=True)):\n",
    "        chunk_count += 1\n",
    "        rows = len(chunk)\n",
    "        total_rows_processed += rows\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"✅ Processed {(i + 1) * chunk_size:,} rows so far...\")\n",
    "\n",
    "        df_clean = chunk.copy()\n",
    "\n",
    "        if 'CANCELLATION_CODE' in df_clean.columns:\n",
    "            df_clean = df_clean.drop(columns=['CANCELLATION_CODE'])\n",
    "\n",
    "        delay_reason_cols = [col for col in df_clean.columns if 'DELAY_DUE_' in col]\n",
    "        for col in delay_reason_cols:\n",
    "            missing_count = df_clean[col].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "                stats['delay'][col] = stats['delay'].get(col, 0) + missing_count\n",
    "\n",
    "        numeric_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "        for col in numeric_cols:\n",
    "            if col not in delay_reason_cols:\n",
    "                missing_count = df_clean[col].isna().sum()\n",
    "                if missing_count > 0:\n",
    "                    median_value = df_clean[col].median()\n",
    "                    df_clean[col] = df_clean[col].fillna(median_value)\n",
    "                    if col not in stats['numeric']:\n",
    "                        stats['numeric'][col] = {'count': 0, 'median': median_value}\n",
    "                    stats['numeric'][col]['count'] += missing_count\n",
    "\n",
    "        categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            missing_count = df_clean[col].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                mode_value = df_clean[col].mode()[0]\n",
    "                df_clean[col] = df_clean[col].fillna(mode_value)\n",
    "                if col not in stats['categorical']:\n",
    "                    stats['categorical'][col] = {'count': 0, 'mode': mode_value}\n",
    "                stats['categorical'][col]['count'] += missing_count\n",
    "\n",
    "        datetime_cols = df_clean.select_dtypes(include=['datetime64[ns]']).columns\n",
    "        for col in datetime_cols:\n",
    "            missing_count = df_clean[col].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                if col not in datetime_medians:\n",
    "                    datetime_medians[col] = df_clean[col].dropna().median()\n",
    "                df_clean[col] = df_clean[col].fillna(datetime_medians[col])\n",
    "                stats['datetime'][col] = stats['datetime'].get(col, 0) + missing_count\n",
    "\n",
    "        df_clean.to_csv(output_path, mode='a', index=False, header=(i == 0))\n",
    "\n",
    "    print(\"\\n===== FINAL CLEANING SUMMARY =====\")\n",
    "    print(f\"Total chunks processed: {chunk_count}\")\n",
    "    print(f\"Total rows processed: {total_rows_processed}\")\n",
    "\n",
    "    if stats['delay']:\n",
    "        print(\"\\nDelay columns filled with 0:\")\n",
    "        for col, count in stats['delay'].items():\n",
    "            print(f\"  {col}: {count} values filled\")\n",
    "\n",
    "    if stats['numeric']:\n",
    "        print(\"\\nNumeric columns filled with median:\")\n",
    "        for col, info in stats['numeric'].items():\n",
    "            print(f\"  {col}: {info['count']} values filled, median used = {info['median']:.4f}\")\n",
    "\n",
    "    if stats['categorical']:\n",
    "        print(\"\\nCategorical columns filled with mode:\")\n",
    "        for col, info in stats['categorical'].items():\n",
    "            print(f\"  {col}: {info['count']} values filled, mode used = {info['mode']}\")\n",
    "\n",
    "    if stats['datetime']:\n",
    "        print(\"\\nDatetime columns filled with median:\")\n",
    "        for col, count in stats['datetime'].items():\n",
    "            print(f\"  {col}: {count} values filled, median used = {datetime_medians[col]}\")\n",
    "\n",
    "    shutil.move(output_path, abs_input)\n",
    "    print(f\"\\n✅ Original file replaced with cleaned data: {abs_input}\")\n",
    "\n",
    "    return {\n",
    "        \"total_rows\": total_rows_processed,\n",
    "        \"total_chunks\": chunk_count,\n",
    "        \"summary\": stats\n",
    "    }\n",
    "\n",
    "\n",
    "# Run the function\n",
    "result = handle_missing_values(operational_flights_path, chunk_size=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e25a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1d0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca60aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbb564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed18f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
